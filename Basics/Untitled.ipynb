{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a891d754-e2b4-4c34-9913-e6d226487ecb",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98316464-d07d-4412-9ce6-2bf90589bd99",
   "metadata": {},
   "source": [
    "## 1- Tokenization Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e342c5-84c2-4ca2-a841-79cb53140c41",
   "metadata": {},
   "source": [
    "- \"i like apple\". Tokenization is the process of decomposing the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c5495b-aeac-4846-ab7e-c39ef4e54173",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"The sun dipped below the horizon, casting a warm glow across the tranquil landscape.\" \n",
    "s2 = \"A gentle breeze rustled the leaves, creating a soothing melody in the quiet evening air.\"\n",
    "s3 = \"As shadows lengthened, the world seemed to slow down, embracing the serenity of the approaching night.\"\n",
    "s4 = \"In that moment, nature whispered its timeless secrets to those willing to listen.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a44073e-818c-4a91-aff7-beae3b426af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "## to download models\n",
    "import spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82b1537-1e58-4670-bd6f-23bc290fab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\") # load function is to load pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a600fa45-b97d-48f4-8aea-0bca9add0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27f43b4f-ad6c-4603-afee-2fa9d5619240",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_1 = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8072571d-f8e8-416a-9965-a471c438274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp_1(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc5ca1b1-0ba8-4994-a5ab-15e7007ed4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "sun\n",
      "dipped\n",
      "below\n",
      "the\n",
      "horizon\n",
      ",\n",
      "casting\n",
      "a\n",
      "warm\n",
      "glow\n",
      "across\n",
      "the\n",
      "tranquil\n",
      "landscape\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d609a7b-6032-4d51-8194-1928922fd9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80a1ee9-5ca9-49c7-a3a0-7921bafa009e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc1) # it is divided into len(doc1)-tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aca50-703c-4105-83d5-5c5f225eb85c",
   "metadata": {},
   "source": [
    "## 2- Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d12e4-191b-42ad-a1aa-661c998e90df",
   "metadata": {},
   "source": [
    "- Stemming : finding the root of the word.\n",
    "- Lemmatization : give root that is in the vocabulary\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b237c-bb22-4104-93f4-bd5f77ab7965",
   "metadata": {},
   "source": [
    "### a) Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f525cbd6-8d61-4497-9fe1-d295f0f8f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =['run','runner' ,'running','ran','runs','easily',\"fairly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e15bc87-8d45-4235-b167-0e87657b9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87acedc3-dce2-4e66-8e49-48fe895ed8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "s_stemmer = SnowballStemmer(language=\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17c2bb1-e637-400f-8aa5-1f6bdbad3ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run------>run\n",
      "runner------>runner\n",
      "running------>run\n",
      "ran------>ran\n",
      "runs------>run\n",
      "easily------>easili\n",
      "fairly------>fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\"------>\"+ p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a7343af-2f22-48c9-a7a0-4b7db11e83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run------>run\n",
      "runner------>runner\n",
      "running------>run\n",
      "ran------>ran\n",
      "runs------>run\n",
      "easily------>easili\n",
      "fairly------>fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\"------>\"+ s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22e7fa-3529-4f06-830e-8cef1b0cc3e3",
   "metadata": {},
   "source": [
    "### b) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c47ae9b-00f0-4fbc-9bb8-f45710f19df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4365d937-99fe-4597-ba0f-ea4daf1c67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"RESTful API training This framework covers almost all the different aspects of API writing and contains a set of practical tools.\"\n",
    "doc1 = nlp(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc2a19b8-5da8-4f12-8f89-7c727af991f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTful \t RESTful\n",
      "API \t api\n",
      "training \t train\n",
      "This \t this\n",
      "framework \t framework\n",
      "covers \t cover\n",
      "almost \t almost\n",
      "all \t all\n",
      "the \t the\n",
      "different \t different\n",
      "aspects \t aspect\n",
      "of \t of\n",
      "API \t api\n",
      "writing \t writing\n",
      "and \t and\n",
      "contains \t contain\n",
      "a \t a\n",
      "set \t set\n",
      "of \t of\n",
      "practical \t practical\n",
      "tools \t tool\n",
      ". \t .\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text , \"\\t\",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da20d846-cbaa-4fd0-9bd0-7fa3a72df5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTful------>rest\n",
      "API------>api\n",
      "training------>train\n",
      "This------>thi\n",
      "framework------>framework\n",
      "covers------>cover\n",
      "almost------>almost\n",
      "all------>all\n",
      "the------>the\n",
      "different------>differ\n",
      "aspects------>aspect\n",
      "of------>of\n",
      "API------>api\n",
      "writing------>write\n",
      "and------>and\n",
      "contains------>contain\n",
      "a------>a\n",
      "set------>set\n",
      "of------>of\n",
      "practical------>practic\n",
      "tools.------>tools.\n"
     ]
    }
   ],
   "source": [
    "for word in text.split():\n",
    "    print(word +\"------>\"+ p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c069c82-8fbc-4cc5-b0cf-65fe808db2f2",
   "metadata": {},
   "source": [
    "## 3- Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765f5c0-e816-4728-8499-099a2cddcebd",
   "metadata": {},
   "source": [
    "a an the always ........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06a4eee1-07ef-4e70-86b2-6276e451e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a890329-0bdf-4d90-a80e-50c1a0ac2e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'take', 'always', 'their', 'yours', 'a', 'say', 'herein', 'might', 'everywhere', 'for', 'did', 'other', 'anyone', 'on', 'same', \"'ll\", 'already', 'done', 'ca', 'regarding', 'besides', 'latterly', 'serious', 'hereupon', 'keep', 'eight', 'anything', 'last', 'he', 'she', 'through', 'from', 'an', 'its', 'become', 'thus', 'latter', 'own', 'any', 'using', 'almost', 'should', 'can', 'some', 'within', 'bottom', 'your', 'make', 'thence', 'two', 'after', 'nobody', 'until', 'former', 'yet', 'yourselves', 'â€˜re', 'due', 'all', 'first', 'part', 'became', 'across', 'â€™s', 'somehow', 'towards', 'seemed', 'put', 'ours', 'of', 'doing', 'per', 'anyhow', 'few', 'made', 'fifty', 'seeming', 'but', 'where', 'just', 'you', 'next', 'so', 'otherwise', 'by', 'ourselves', 'around', 'up', 'back', 'with', 'this', 'again', 'me', 'we', 'â€˜ve', 'could', 'still', 'then', 'below', 'go', 'ten', 'namely', 'nothing', 'throughout', 'often', \"'re\", 'these', 'seem', 'beside', 'each', 'nâ€˜t', 'along', 'nor', 'name', 'call', 'most', 'together', 'sixty', 'formerly', 'thereafter', 'somewhere', 'however', 'really', 'beyond', 'â€™ve', 'above', 'eleven', 'onto', 'whence', 'whole', 'nevertheless', 'how', 'who', 'twelve', 'becoming', 'alone', 'that', 'neither', 'seems', 'though', 'everyone', 'have', 'get', \"n't\", 'also', 'before', 'my', 'hundred', 'his', 'â€˜s', 'is', 'beforehand', 'moreover', 'hence', 'whoever', 'him', 'thereupon', 'has', 'whither', 'they', 'itself', 'i', 'front', 'mine', 'everything', 'something', 'cannot', 'when', 'five', 'out', 'toward', 'meanwhile', 'than', 'â€˜ll', 'empty', 'behind', 'please', 'between', 'less', 'whereby', 'whereafter', 'â€™d', 'against', 'whether', 'am', 'which', 'nowhere', 'in', 'indeed', 'â€™ll', 'himself', 'were', 'being', 'may', 'them', 'here', 'too', 'because', 'whereas', 'will', 'among', 'and', 'else', 'would', 'â€˜d', 'another', 'at', 'themselves', 'while', 'whereupon', 'whenever', 'whom', 'be', 'via', \"'s\", 'her', 'been', 'was', 'others', 'whatever', 'under', 'both', 'our', 'to', 'about', 'anywhere', 'enough', 'side', 'wherever', 'three', 'even', 'very', 'see', 'well', 'third', 'sometime', 'every', 'noone', 'nine', 'now', 'what', 'twenty', 'mostly', 'upon', 'therefore', 'during', 'ever', 'only', 'yourself', 'over', 'although', 'many', 'â€™m', 'therein', 'as', 'one', 'several', 'none', 'show', 'perhaps', 'hers', 'either', 'herself', 'least', 'it', 'six', 'hereby', \"'m\", 'nâ€™t', 'the', 'quite', 'does', 'never', 'top', 'â€˜m', 'four', 'â€™re', 'elsewhere', 'thereby', 'used', 'why', 'myself', 'hereafter', 'forty', 'further', 'give', 'or', 'unless', 'fifteen', 'afterwards', 'not', 'except', 're', 'sometimes', 'off', 'becomes', 'must', 'full', 'no', 'us', 'rather', 'whose', 'are', 'move', 'amount', 'do', 'such', 'wherein', 'since', \"'d\", \"'ve\", 'those', 'if', 'had', 'into', 'down', 'more', 'without', 'there', 'various', 'amongst', 'much', 'someone', 'once', 'thru', 'anyway'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd479387-a734-4c28-93d2-ba94104bb75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc22bb6b-c9b5-48df-a787-c311cbdb7d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a word is a stop word or not\n",
    "nlp.vocab[\"always\"].is_stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6137e21-49eb-4e82-a682-565f4fe5a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove/add....(.stop_words.chose) a keyword form stop word\n",
    "nlp.Defaults.stop_words.remove(\"wait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01b92c4a-b143-40a9-8a8f-bbe9d8aee373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45d155-28b7-4f8c-9221-56eb1cdb09e4",
   "metadata": {},
   "source": [
    "## 4- Vocabulary and Matching\n",
    "- best use case is this website : https://explosion.ai/software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec35289-6483-4d0f-8b38-f1913b947df9",
   "metadata": {},
   "source": [
    "### A) Rule-Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6afb5ed-1116-45bb-ac5b-6ec4495f2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab) # Create Matcher object and pass nlp.vocab\n",
    "\n",
    "# here matcher is an object that pairs to current Vocab object\n",
    "# we can add and remove specific named matchers to matcher as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cd6664e-80bf-43a5-9fbb-8a43677ced5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list , and inisde that list add series of dictionaries.\n",
    "# hello world can appear in the following :\n",
    "# 1 - hello world\n",
    "# 2-  hello-world\n",
    "pattern_1 = [{\"LOWER\":\"hello\"},{\"LOWER\":\"world\"}]\n",
    "pattern_2 = [{\"LOWER\":\"hello\"},{\"IS_PUNCT\":True},{\"LOWER\":\"world\"}]\n",
    "# 'LOWER',\"IS_PUNCT\" are the attributes\n",
    "# they has to be written in that way only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c653648-1238-46bc-afd4-01cf19796496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add patterns to matchers object\n",
    "# Add a match rule to matcher , A match rule consist of ,\n",
    "# 1) an ID key\n",
    "# 2) an onmatch callback\n",
    "# 3) one or more patterns\n",
    "matcher.add(key=\"hello world\",on_match=None ,patterns=[pattern_1 , pattern_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dc5768a-a205-4046-ac2a-567c8380d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"'hello world' are the first two printed words for most of the programmers , printing 'hello world'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd684e58-0093-486f-84f5-7c9c555d1ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world' are the first two printed words for most of the programmers , printing 'hello world'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fe7e1-9fcf-4db2-a643-61ba983710c9",
   "metadata": {},
   "source": [
    "#### Finding matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ba5dcf8-2b7d-4b08-ad34-768d203c33fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2758594965276909933, 1, 3), (2758594965276909933, 18, 20)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_matches = matcher(doc) # passing doc to matcher object and store this in a variable\n",
    "\n",
    "find_matches\n",
    "# it returns output list of tuples\n",
    "# string ID , index start and index end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a034c76c-d58f-4486-89e2-6971fa4c8106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2758594965276909933 hello world 1 3 hello world\n",
      "2758594965276909933 hello world 18 20 hello world\n"
     ]
    }
   ],
   "source": [
    "# define a function to find the matches\n",
    "for match_id , start , end in find_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc[start:end]\n",
    "    print(match_id , string_id , start , end , span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f70cdd8-f704-4fcc-8e7b-96192277785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove matches\n",
    "matcher.remove('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf765d-a958-4df6-9b58-48dd83e9a182",
   "metadata": {},
   "source": [
    "###  Setting patterns options and quantifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f04cd38a-47a9-4b2b-a1d4-b6a2c6e759d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the patterns:\n",
    "pattern_3 = [{'LOWER':\"hello\"},{'LOWER':'world'}]\n",
    "pattern_4 = [{'LOWER':\"hello\"},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'world'}]\n",
    "# 'OP':'*' ->>>> this is going to allow this pattern to match zero or more times for any punctuation\n",
    "\n",
    "# Add the new set of patterns to the 'hello world' matcher:\n",
    "matcher.add(key='Hello World' , on_match=None , patterns= [pattern_3,pattern_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1092a91e-a6c7-4099-b571-b06451369773",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_2 = nlp('you can print Hello World or hello world or Hello-World')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eddf06f0-91d2-46b2-a732-2e3743e24a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8585552006568828647, 3, 5),\n",
       " (8585552006568828647, 6, 8),\n",
       " (8585552006568828647, 9, 12)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_matches = matcher(doc_2)\n",
    "find_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e25a71-90d3-47d7-9eb1-0608fc19a39e",
   "metadata": {},
   "source": [
    "### B)Phrase Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9a20caf-555f-4297-a12f-4b5868326d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp  = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdafefe1-0607-4f0f-b97c-1a6f2ac18bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the PhraseMatcher library\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be7ec68c-d563-44a7-8992-2b96cd373b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['Barack Obama',\"Angela Markel\",\"Washington\",\"D.C.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f6d8445-e5d2-476a-8456-6f579a58f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each phrase to a document object\n",
    "phrase_patterns = [nlp(text) for text in phrase_list] # to do that we are using list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33ea1754-296c-421d-bebc-b3118392ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Barack Obama, Angela Markel, Washington, D.C.]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns # phrase object are not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e4fe43e-ae43-422e-828d-629fe659b358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns[0])\n",
    "# they are the spacy docs\n",
    "# that's why we don't have any quotes there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21c3363c-6029-466a-8c06-2bb50f746b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass each doc object into the matcher\n",
    "matcher.add('TerminologyList',None,*phrase_patterns)\n",
    "# that's we have to add astrisk mark before phrase_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81ed3149-086f-426a-a3c8-2ee13bee31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_3 = nlp(\"German CHancellor Angela Markel and US President Barack Obama\"\n",
    "           \"converse in the Oval office inside the white house in Washington, D.C.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55f5d9c5-7247-45a0-9bf6-785cd42416a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3766102292120407359, 2, 4),\n",
       " (3766102292120407359, 18, 19),\n",
       " (3766102292120407359, 20, 21)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_matches= matcher(doc_3)\n",
    "find_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "580d441a-ce8f-4cef-80bf-6faf36e5267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3766102292120407359 TerminologyList 2 4 Angela Markel\n",
      "3766102292120407359 TerminologyList 18 19 Washington\n",
      "3766102292120407359 TerminologyList 20 21 D.C.\n"
     ]
    }
   ],
   "source": [
    "# define a function to find the matches \n",
    "for match_id , start , end in find_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc_3[start:end]\n",
    "    print(match_id, string_id ,start , end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79d264-b68b-4633-b674-d413ee2417c1",
   "metadata": {},
   "source": [
    "## 5- Parts of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0a4af6b-8fb5-4a97-99a7-36a64ed14403",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 =\"Apple is looking at buying U.K. startup for $1 billion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a013e77-93a7-4067-974f-aa53c2fed725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(name=\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0bcee952-3cf3-4297-8ae5-034133333d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b0a63ade-dc0d-42ed-93f3-de06d29ad461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN NNP noun, proper singular\n",
      "is AUX VBZ verb, 3rd person singular present\n",
      "looking VERB VBG verb, gerund or present participle\n",
      "at ADP IN conjunction, subordinating or preposition\n",
      "buying VERB VBG verb, gerund or present participle\n",
      "U.K. PROPN NNP noun, proper singular\n",
      "startup NOUN NN noun, singular or mass\n",
      "for ADP IN conjunction, subordinating or preposition\n",
      "$ SYM $ symbol, currency\n",
      "1 NUM CD cardinal number\n",
      "billion NUM CD cardinal number\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text , token.pos_ , token.tag_ ,spacy.explain(token.tag_))\n",
    "    # spacy.explain() is for explaing each token method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4f3f151-3968-41a0-aaf3-a31a54859509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 PROPN 2\n",
      "87 AUX 1\n",
      "100 VERB 2\n",
      "85 ADP 2\n",
      "92 NOUN 1\n",
      "99 SYM 1\n",
      "93 NUM 2\n"
     ]
    }
   ],
   "source": [
    "# getting noun .. etc\n",
    "for key , val in doc.count_by(spacy.attrs.POS).items():\n",
    "    print(key,doc.vocab[key].text,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be31c5a3-ed9a-4221-95c0-4c62139fd762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77a59e7b-123b-4e91-9b71-345a12c0add8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4fe70cf1a77748d5a13d37f22fe14116-0\" class=\"displacy\" width=\"1150\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,52.0 245.0,52.0 245.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,102.0 240.0,102.0 240.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-2\" stroke-width=\"2px\" d=\"M270,152.0 C270,102.0 340.0,102.0 340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340.0,154.0 L348.0,142.0 332.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-3\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M440.0,154.0 L448.0,142.0 432.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-4\" stroke-width=\"2px\" d=\"M470,152.0 C470,102.0 540.0,102.0 540.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M540.0,154.0 L548.0,142.0 532.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-5\" stroke-width=\"2px\" d=\"M470,152.0 C470,52.0 645.0,52.0 645.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M645.0,154.0 L653.0,142.0 637.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-6\" stroke-width=\"2px\" d=\"M470,152.0 C470,2.0 750.0,2.0 750.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,154.0 L758.0,142.0 742.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-7\" stroke-width=\"2px\" d=\"M870,152.0 C870,52.0 1045.0,52.0 1045.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,154.0 L862,142.0 878,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-8\" stroke-width=\"2px\" d=\"M970,152.0 C970,102.0 1040.0,102.0 1040.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,154.0 L962,142.0 978,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4fe70cf1a77748d5a13d37f22fe14116-0-9\" stroke-width=\"2px\" d=\"M770,152.0 C770,2.0 1050.0,2.0 1050.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4fe70cf1a77748d5a13d37f22fe14116-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1050.0,154.0 L1058.0,142.0 1042.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docs=doc , style=\"dep\" , jupyter=True ,options={\"distance\":100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8e493-278d-4ee5-9f84-964878b04bc3",
   "metadata": {},
   "source": [
    "## 6- Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f1219f81-ae96-45f0-abdf-9c3b1f7549fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Hello, how are you today?\"\n",
    "s2 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "s3 = \"123 Main Street, Anytown, USA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "22b5e4c2-cf48-4dc3-ae82-a2d5fbee61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98b7aac1-9ad7-42ca-9815-c0c5dab66f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = nlp(s1)\n",
    "doc_2 = nlp(s2)\n",
    "doc_3 = nlp(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "463812ea-8c53-42ec-b09d-ece45896c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((today,), (), (123, Main Street, Anytown, USA))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1.ents , doc_2.ents , doc_3.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "75caa91f-d423-4c8c-b64e-17fadc1f99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 CARDINAL Numerals that do not fall under another type\n",
      "Main Street FAC Buildings, airports, highways, bridges, etc.\n",
      "Anytown GPE Countries, cities, states\n",
      "USA GPE Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "for i in doc_3.ents:\n",
    "    print(i.text , i.label_ , str(spacy.explain(i.label_)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3a4a175f-a344-462d-921f-d9f296ee7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG = doc_1.vocab.strings['ORG']\n",
    "from spacy.tokens import Span\n",
    "new_ent = Span(doc_1 , 4,5,label =ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0958236a-df1f-4242-ba8c-aa559a03f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1.ents = list(doc_1.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c23984b8-ac50-4f9e-aee4-4ef6ee53eb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(you, today)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ab242bfc-3bd1-46d0-b705-479fd311b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you ORG Companies, agencies, institutions, etc.\n",
      "today DATE Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "for i in doc_1.ents:\n",
    "    print(i.text , i.label_ , str(spacy.explain(i.label_)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3cf14b11-8785-48fa-af93-c84ae4306f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello, how are \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    you\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(docs = doc_1 , style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ecddb639-bbf2-4fdd-b7cc-772ca284b243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello, how are \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    you\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " today?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docs = doc_1 , style=\"ent\",jupyter=True , options={\"ents\":['ORG']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7dd9cd-d6b1-42fc-bb7b-23fc5f75abb8",
   "metadata": {},
   "source": [
    "## 7- Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "83cbe3ab-669a-48c8-aee4-b59cd2e04161",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"123 Main Street; Anytown; USA\"\n",
    "s2 = \"123 Main Street. Anytown. USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2db755b1-bbf8-404b-9493-4ac43fc1dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "aa3eb36a-0f33-435d-aa01-f07ff514e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = nlp(s1)\n",
    "doc_2 = nlp(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8a62d3af-c243-45d0-b9c8-1dc504e9ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Main Street; Anytown; USA\n"
     ]
    }
   ],
   "source": [
    "for i in doc_1.sents:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e8ecbc43-730f-46d1-bd71-bdc2e65fdc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"123 Main Street U.K. . Anytown. USA\"\n",
    "#s3 = \"123 Main Street U.K.. Anytown. USA\"\n",
    "\n",
    "doc_3 = nlp(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9e678103-81dd-4e2d-8152-91ec9799ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Main Street U.K. .\n",
      "Anytown.\n",
      "USA\n"
     ]
    }
   ],
   "source": [
    "for i in doc_3.sents:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7eb250ef-6f00-446f-8860-9c9d6508c40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8fcd622e-f1bf-4d5a-823b-58947e8ae535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123 Main Street; Anytown; USA'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "83dabf3a-99d5-417b-af60-374cb953caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding new transformers\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d18a96be-93ca-488d-b64d-7b642243bd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7174d423-7e82-475f-9a37-990e9a92040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Main Street;\n",
      "Anytown;\n",
      "USA\n"
     ]
    }
   ],
   "source": [
    "doc_1 = nlp(s1)\n",
    "for i in doc_1.sents:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4c177-7f1c-44e8-8050-ff85af4dc448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
